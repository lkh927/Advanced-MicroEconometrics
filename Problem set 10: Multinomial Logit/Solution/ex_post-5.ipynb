{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import default_rng\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import mlogit_post as mlogit\n",
    "import estimation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "============\n",
    "\n",
    "In this week's problem set, you are asked to investigate how alcohol\n",
    "abuse affects employment status. Individuals can either be outside of\n",
    "the labour market, unemployed or employed. This means, that the\n",
    "dependent variable has three discrete outcomes. We use the multinomial\n",
    "logit model to express the probability of individuals to be either\n",
    "outside the labour market, unemployed or employed. This model is a\n",
    "generalization of the logit model we looked at in problem set 9 (binary\n",
    "choice) which only allowed for the dependent variable to have two\n",
    "discrete outcomes.\n",
    "\n",
    "The dataset consists of two things for each $i$, $(y_i, \\mathbf{x}_i)$, \n",
    "where $y_i \\in \\{1,...,J\\}$, and $\\mathbf{x}_i$ is a $K\\times 1$ vector \n",
    "of explanatory variables relating to the individuals. \n",
    "\n",
    "In the multinomial logit the probability of observing choice $j$ for\n",
    "household $i$ given the observed explanatory variables, $\\mathbf{x}_{i}$ is given\n",
    "as,\n",
    "$$\n",
    "\\text{Pr}\\left(y_{i}=j\\mid \\mathbf{x}_{i},\\boldsymbol{\\beta}_j\\right) \\equiv p_{ij}\n",
    "    =\\frac{\\exp( \\mathbf{x}_{i}\\boldsymbol{\\beta}_j )}\n",
    "          {\\sum_{k=1}^{J}\\exp\\left(\\mathbf{x}_{i}\\boldsymbol{\\beta}_k\\right)}\n",
    "          ,\\quad j=1,\\dots J \\tag{1}\n",
    "$$\n",
    "\n",
    "The probabilities lie between 0 and 1 since\n",
    "$\\exp(\\mathbf{x}_{i}\\boldsymbol{\\beta}_j)>0$ and they sum to one over the\n",
    "$J$ alternatives. The expression,\n",
    "(1), can be derived from an underlying latent\n",
    "utility model, where taste shocks follow an extreme value type 1\n",
    "distribution. The data-generating process of this latent utility model\n",
    "can be formalized as\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{i} &= \\operatorname*{argmax}_{j=1,\\ldots,J} \\{u_{ij}\\},  \\tag{2} \\\\\n",
    "u_{ij} &= \\mathbf{x}_{i} \\boldsymbol{\\beta}_j + \\varepsilon_{ij}, \\qquad \\varepsilon_{ij} \\sim \\text{IID Extreme Value} , \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where the utility, $u_{ij}$, consists of a deterministic part,\n",
    "$v_{ij}=\\mathbf{x}_i\\boldsymbol{\\beta}_j$, and a stochastic part, $\\varepsilon_{ij}$. Individual\n",
    "$i$ chooses the alternative $y_i\\in \\{1,\\ldots,J\\}$ that is associated\n",
    "with the highest level of $u_{ij}$ after having observed the iid extreme\n",
    "value type 1 distributed shocks, $\\varepsilon_{ij}$ for\n",
    "$j\\in\\{1,\\ldots,J\\}$. It is important to note that the individual \n",
    "observes everything in $u_{ij}$, so it is a simple thing to pick the \n",
    "$j$ that has the highest utility. The challenge for the econometrician is \n",
    "that the error terms $\\varepsilon_{ij}$ are not in the dataset. \n",
    "\n",
    "Fortunately, it can be shown that if one simulates data according to the \n",
    "Data Generating Process (DGP) above, then the choice probabilities in (1) \n",
    "are correct.\n",
    "\n",
    "It turns out that the model is only identified under a *normalization \n",
    "assumption*, such as $\\boldsymbol{\\beta}_1 := \\mathbf{0}_{K\\times 1}$.\n",
    "That is, we cannot identify a parameter on a regressor, $\\beta_{kj}$, \n",
    "for all alternatives $j=1,...,J$. The argument why this is the case is \n",
    "presented in this youtube video: https://youtu.be/IeDJN6VQtLg. \n",
    "Intuitively, the argument boils down to the fact that we can only identify \n",
    "effects that change the utilty of an option *relative* to other options. \n",
    "This is because we only observe the *argmax* of utility and thus cannot \n",
    "hope to identify the *scale* of utility, since utility is merely ordinal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Simulate Data \n",
    "\n",
    "The first task is to finish the code in the function\n",
    "`sim_data(N, J, theta)` in the `mlogit` module. This\n",
    "function simulates a data set with $n$ individuals choosing between $j$ alternatives. The third input is a parameter vector,\n",
    "$\\theta=(\\beta_1^\\prime,\\ldots,\\beta_J^\\prime)^\\prime$ and $j=1$ is the baseline alternative $\\beta_1=0$.\n",
    "\n",
    "The function simulates a $N \\times K$ matrix of covariates. These\n",
    "consist of a constant term and K-1 individual characteristics drawn from a standard normal distribution, i.e.\n",
    "$x_{i}= (1,x_{i2}, \\ldots, x_{iK})'$, with $x_{ik} \\sim N(0,1)$.\n",
    "\n",
    "The choice pattern is simulated in accordance with the data generating\n",
    "process given by the equations\n",
    "(2) - (3).\n",
    "\n",
    "*Note:*\n",
    "The solution to this is exactly as we simulated data for the clogit last week. The main difference is that we now have beta coefficients for each option (last week we had one column of beta coefficients, today we have (J - 1) columns of beta coefficients.). As mentioned, we use the first option J = 0 as a baseline.\n",
    "\n",
    "***Programming hint:*** We will simulate `x` as `(N, K)`, i.e. there is no column for the normalized alternative. We can still use matrix algebra to compute the $N \\times J$ matrix of utilities with characteristic element \n",
    "$$ v_{ij} = \\sum_{k=1}^K x_{ijk} \\beta_{jk} \\quad \\text{for } \\ne 1,$$ \n",
    "and $v_{i1} = 0$. We can compute this using \n",
    "```Python\n",
    "xb = x @ theta # x is (N, K) and theta is (K, J-1), so the product is (N, J-1)\n",
    "oo = np.zeros((N,1)) # normalized util=0 for the baseline\n",
    "u = np.hstack([oo,xb]) # full (N,J) matrix of utilities (hstack = horizontal stack)\n",
    "```\n",
    "The product `x @ theta` works because `x` is `(N,J-1,K)` and `theta` is `(K,J-1)`. Then Python interprets it as we expect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize simulation parameters\n",
    "N = 10000\n",
    "J = 3\n",
    "K = 2\n",
    "\n",
    "# Initialize true beta coefficients for data generating process.\n",
    "beta2 = np.array([[-.3, .6]]).T\n",
    "beta3 = np.array([[.2, -1]]).T\n",
    "true_beta = np.hstack([beta2, beta3])\n",
    "theta0 = np.zeros((K, J - 1)) # zeros are safe starting vlaues, resulting in equal probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate some data \n",
    "np.random.seed(1)\n",
    "y,x = mlogit.sim_data(true_beta, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies of y:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    4250\n",
       "0    2943\n",
       "1    2807\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Frequencies of y:')\n",
    "pd.value_counts(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Choice Probabilities \n",
    "\n",
    "The choice probabilities in the multinomial logit model is given by\n",
    "equation (1). This should be implemented into the mlogit.m\n",
    "class file such that the function\n",
    "`choice_prob()` returns choice probabilities, $p_{ij}$ for\n",
    "$i\\in \\{1,\\ldots,N\\}$ and $j\\in \\{1,\\ldots,J\\}$. The choice\n",
    "probabilities are contained in the ($N \\times J$) matrix `ccp`. The function should also return the (natural)\n",
    "$\\log$ of the choice probabilities which is used later in the maximum\n",
    "likelihood estimation. The log transformed choice probabilities, which should be saved in the matrix `logccp`,\n",
    "are given by\n",
    "$$\n",
    "\\log\\text{Pr}\\left(y_{i}=j\\mid \\mathbf{x}_{ij},\\boldsymbol{\\beta}\\right)=\\log p_{ij}=\\mathbf{x}_{i}\\boldsymbol{\\beta}_j-\\log\\left(\\sum_{m=1}^{J}\\exp\\left(\\mathbf{x}_{i}\\boldsymbol{\\beta}_m\\right)\\right),\n",
    "$$\n",
    "\n",
    "*Programming hint*:\n",
    "Again, this is done exactly like last week, except that you need a loop for each column of coefficients we have for the choices when you calculate the utility matrix. Remember that the first column in the utility matrix is the baseline, and therefore should be a column with only zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp, logccp = mlogit.choice_prob(theta0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp, logccp = mlogit.choice_prob(true_beta, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Estimate on Simulated Data\n",
    "\n",
    "Last time you created the criterion function for the conditional logit estimator. This is identical to the same criterion function for the multinomial logit model, so you need only to copy this from last week.\n",
    "\n",
    "Now estimate the coefficients based on the simulated data, using maximum likelihood to solve the model. To do this use the `nlm.estimate()` function.\n",
    "\n",
    "I have written some code that calculates the norm of the gradient at the point of the solution. We will use this later to solve any issues we might have in a real, empirical example. Should this norm be large or small?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.932552\n",
      "         Iterations: 17\n",
      "         Function evaluations: 90\n",
      "         Gradient evaluations: 18\n"
     ]
    }
   ],
   "source": [
    "sim_result = estimation.estimate(mlogit.q, theta0, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Est</th>\n",
       "      <th>s.e.</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x21</th>\n",
       "      <td>-0.2973</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x22</th>\n",
       "      <td>0.1944</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x31</th>\n",
       "      <td>0.5909</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x32</th>\n",
       "      <td>-1.0230</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Est    s.e.  True\n",
       "x21 -0.2973  0.0306  -0.3\n",
       "x22  0.1944  0.0264   0.2\n",
       "x31  0.5909  0.0321   0.6\n",
       "x32 -1.0230  0.0314  -1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varnames = [f'x{j+1}{k+1}' for j in range(1,J) for k in range(K)]\n",
    "pd.DataFrame({\n",
    "              'Est' : sim_result[\"theta\"], \n",
    "              's.e.': sim_result[\"se\"], \n",
    "              'True': true_beta.flatten() # pd expects flat arrays \n",
    "             },\n",
    "             index=varnames).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_norm(q, theta):\n",
    "    g = estimation.centered_grad(q, theta) # (N,K)\n",
    "    g = np.mean(g, axis=0) # (K,)\n",
    "    return np.mean(g ** 2) # 2-norm: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q(thetahat)        =   0.9326\n",
      "2-norm of gradient =  2.77e-11\n"
     ]
    }
   ],
   "source": [
    "q = lambda theta: np.mean(mlogit.q(theta, y, x))\n",
    "print(f'q(thetahat)        = {q(sim_result[\"theta\"]): 8.4g}')\n",
    "print(f'2-norm of gradient = {calc_norm(q, sim_result[\"theta\"]): 8.4g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Estimation on the Terza (2002) data\n",
    "\n",
    "We are now going to use the data from \n",
    ">   Joseph V. Terza (2002): \"Alcohol abuse and employment: A second look\"\n",
    ">   Journal of Applied Econometrics, Volume 17, Issue 4, Pages 393-404\n",
    "\n",
    "Data source: http://qed.econ.queensu.ca/jae/2002-v17.4/terza/\n",
    "\n",
    "\n",
    "We will use the data to estimate the\n",
    "multinomial logit model. Therefore, we need to first load the data and\n",
    "then use the proper functions coded previously. \n",
    "\n",
    "The outcome, `y`, can take $J = 3$ values: \n",
    "* `0` if they are out of the work force, \n",
    "* `1` if they are unemployed, and \n",
    "* `2` if they are employed. \n",
    "\n",
    "Out of the work force, `0`, will be the normalized baseline alternative for our analysis.\n",
    "\n",
    "The results we are looking to obtain are shown in the table below, although some of them are rescaled, so you might have too many commas for some coefficients:\n",
    "\n",
    "|           |   Unemployed |   (t, unemployed) |    Employed |   (t, employed) |\n",
    "|:----------|-------------:|------------------:|------------:|----------------:|\n",
    "| alcohol   |   0.126952   |         0.584267  | -0.153571   |       -1.08658  |\n",
    "| urate     |   0.0457542  |         0.83962   | -0.0955165  |       -2.78256  |\n",
    "| age       |   0.162471   |         2.41517   |  0.227685   |        5.44668  |\n",
    "| agesq     |  -0.00244618 |        -3.0253    | -0.00308571 |       -6.33359  |\n",
    "| schooling |  -0.00923555 |        -0.340401  |  0.0890395  |        6.04366  |\n",
    "| married   |   0.400316   |         2.1345    |  0.708421   |        6.17536  |\n",
    "| famsize   |   0.0621845  |         1.24317   |  0.0622035  |        1.96377  |\n",
    "| white     |   0.0391827  |         0.221582  |  0.738065   |        7.0695   |\n",
    "| excellent |   2.91856    |         6.41338   |  3.70305    |       20.4199   |\n",
    "| verygood  |   2.97854    |         6.47601   |  3.65356    |       19.507    |\n",
    "| good      |   2.49418    |         5.5087    |  2.99973    |       17.2925   |\n",
    "| fair      |   1.46049    |         2.98686   |  1.87639    |       10.2903   |\n",
    "| northeast |   0.0843054  |         0.349563  |  0.0887303  |        0.592707 |\n",
    "| midwest   |   0.0155177  |         0.0739923 |  0.122884   |        0.944845 |\n",
    "| south     |   0.174895   |         0.840669  |  0.439299   |        3.44955  |\n",
    "| center    |  -0.271521   |        -1.38227   | -0.268834   |       -2.21096  |\n",
    "| other     |  -0.091874   |        -0.472643  |  0.0980203  |        0.7822   |\n",
    "| firstq    |   0.422726   |         2.08176   | -0.0272806  |       -0.209783 |\n",
    "| secondq   |  -0.0214781  |        -0.100532  | -0.11056    |       -0.868604 |\n",
    "| thirdq    |  -0.0361932  |        -0.166545  | -0.0529623  |       -0.412258 |\n",
    "| const     |  -6.12662    |        -4.12252   | -6.24737    |       -6.66383  |\n",
    "\n",
    "Final likelihood: `q = 0.3276` \n",
    "\n",
    "```      \n",
    "     Value of the log-likehood function: -3217.48\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have written the code to load the data. Use this data to estimate a multinomial logit model using the `nlm.estimate()` function, and print it out using the `nlm.print_table()` function.\n",
    "\n",
    "You might get an error that states that the minimizer is unsure whether it found a solution. Reuse the code from above and check the size of the norm at the solution. Remember that you have to redefine `q` as well. Does the norm look fine to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labor outcome</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>urate</th>\n",
       "      <th>age</th>\n",
       "      <th>agesq</th>\n",
       "      <th>schooling</th>\n",
       "      <th>married</th>\n",
       "      <th>famsize</th>\n",
       "      <th>white</th>\n",
       "      <th>excellent</th>\n",
       "      <th>...</th>\n",
       "      <th>good</th>\n",
       "      <th>fair</th>\n",
       "      <th>northeast</th>\n",
       "      <th>midwest</th>\n",
       "      <th>south</th>\n",
       "      <th>center</th>\n",
       "      <th>other</th>\n",
       "      <th>firstq</th>\n",
       "      <th>secondq</th>\n",
       "      <th>thirdq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8627</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labor outcome  alcohol  urate   age   agesq  schooling  married   \n",
       "8627            3.0      0.0    5.7  36.0  1296.0       18.0      1.0  \\\n",
       "2431            3.0      1.0    3.0  26.0   676.0       16.0      0.0   \n",
       "1093            3.0      0.0    3.0  28.0   784.0       12.0      0.0   \n",
       "\n",
       "      famsize  white  excellent  ...  good  fair  northeast  midwest  south   \n",
       "8627      3.0    1.0        1.0  ...   0.0   0.0        0.0      1.0    0.0  \\\n",
       "2431      1.0    1.0        1.0  ...   0.0   0.0        1.0      0.0    0.0   \n",
       "1093      3.0    1.0        0.0  ...   0.0   0.0        1.0      0.0    0.0   \n",
       "\n",
       "      center  other  firstq  secondq  thirdq  \n",
       "8627     0.0    1.0     0.0      0.0     0.0  \n",
       "2431     1.0    0.0     1.0      0.0     0.0  \n",
       "1093     1.0    0.0     1.0      0.0     0.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt('terza.txt') # numpy array \n",
    "\n",
    "# y takes values 0: out of work force, 1: unemployed, 2: employed\n",
    "y_lab = 'Labor outcome'\n",
    "x_lab = ['alcohol', 'urate', 'age', 'agesq', 'schooling', 'married', 'famsize', 'white', \n",
    "         'excellent', 'verygood', 'good', 'fair', \n",
    "         'northeast', 'midwest', 'south', 'center', 'other', \n",
    "         'firstq', 'secondq', 'thirdq']\n",
    "y_values_lab = ['Out of labor force', 'Unemployed', 'Employed']\n",
    "\n",
    "# to inspect in a cleaner way\n",
    "df = pd.DataFrame(data, columns=[y_lab] + x_lab)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[:, 0] - 1  # Subtract 1 to make y base 0\n",
    "x = data[:, 1:]\n",
    "\n",
    "y = y.astype(int)\n",
    "N = y.size\n",
    "\n",
    "# add constant to x \n",
    "oo = np.ones((N, 1))\n",
    "x = np.hstack((data[:, 1:], oo))\n",
    "K = x.shape[1]\n",
    "x_lab.append('const')\n",
    "\n",
    "J = len(np.unique(y))\n",
    "\n",
    "theta0 = np.zeros((K, J-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use estimation.estimate and mlogit.py to estimate the model and print it out nicely. \n",
    "# You should get coefficients that are close to the table above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.327579\n",
      "         Iterations: 285\n",
      "         Function evaluations: 12599\n",
      "         Gradient evaluations: 293\n"
     ]
    }
   ],
   "source": [
    "mlogit_result = estimation.estimate(mlogit.q, theta0, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetahat = mlogit_result['theta'].reshape(K, J-1)\n",
    "t        = mlogit_result['t'].reshape(K, J-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unemployed</th>\n",
       "      <th>(t, unemployed)</th>\n",
       "      <th>Employed</th>\n",
       "      <th>(t, employed)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>0.126942</td>\n",
       "      <td>0.584224</td>\n",
       "      <td>-0.153576</td>\n",
       "      <td>-1.086610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urate</th>\n",
       "      <td>0.045754</td>\n",
       "      <td>0.839617</td>\n",
       "      <td>-0.095516</td>\n",
       "      <td>-2.782555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.162470</td>\n",
       "      <td>2.415161</td>\n",
       "      <td>0.227685</td>\n",
       "      <td>5.446676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agesq</th>\n",
       "      <td>-0.002446</td>\n",
       "      <td>-3.025287</td>\n",
       "      <td>-0.003086</td>\n",
       "      <td>-6.333594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schooling</th>\n",
       "      <td>-0.009235</td>\n",
       "      <td>-0.340397</td>\n",
       "      <td>0.089040</td>\n",
       "      <td>6.043669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>married</th>\n",
       "      <td>0.400315</td>\n",
       "      <td>2.134493</td>\n",
       "      <td>0.708420</td>\n",
       "      <td>6.175355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsize</th>\n",
       "      <td>0.062184</td>\n",
       "      <td>1.243172</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>1.963769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>0.039181</td>\n",
       "      <td>0.221573</td>\n",
       "      <td>0.738064</td>\n",
       "      <td>7.069495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>2.918552</td>\n",
       "      <td>6.413353</td>\n",
       "      <td>3.703053</td>\n",
       "      <td>20.419854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verygood</th>\n",
       "      <td>2.978532</td>\n",
       "      <td>6.475983</td>\n",
       "      <td>3.653558</td>\n",
       "      <td>19.507038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>2.494161</td>\n",
       "      <td>5.508672</td>\n",
       "      <td>2.999723</td>\n",
       "      <td>17.292446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fair</th>\n",
       "      <td>1.460475</td>\n",
       "      <td>2.986829</td>\n",
       "      <td>1.876387</td>\n",
       "      <td>10.290242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>northeast</th>\n",
       "      <td>0.084304</td>\n",
       "      <td>0.349559</td>\n",
       "      <td>0.088733</td>\n",
       "      <td>0.592723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>midwest</th>\n",
       "      <td>0.015510</td>\n",
       "      <td>0.073955</td>\n",
       "      <td>0.122882</td>\n",
       "      <td>0.944832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>south</th>\n",
       "      <td>0.174893</td>\n",
       "      <td>0.840660</td>\n",
       "      <td>0.439300</td>\n",
       "      <td>3.449555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>center</th>\n",
       "      <td>-0.271525</td>\n",
       "      <td>-1.382293</td>\n",
       "      <td>-0.268835</td>\n",
       "      <td>-2.210969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>-0.091876</td>\n",
       "      <td>-0.472651</td>\n",
       "      <td>0.098020</td>\n",
       "      <td>0.782198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firstq</th>\n",
       "      <td>0.422715</td>\n",
       "      <td>2.081702</td>\n",
       "      <td>-0.027288</td>\n",
       "      <td>-0.209837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secondq</th>\n",
       "      <td>-0.021481</td>\n",
       "      <td>-0.100547</td>\n",
       "      <td>-0.110562</td>\n",
       "      <td>-0.868624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thirdq</th>\n",
       "      <td>-0.036188</td>\n",
       "      <td>-0.166521</td>\n",
       "      <td>-0.052961</td>\n",
       "      <td>-0.412249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-6.126585</td>\n",
       "      <td>-4.122494</td>\n",
       "      <td>-6.247362</td>\n",
       "      <td>-6.663820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unemployed  (t, unemployed)  Employed  (t, employed)\n",
       "alcohol      0.126942         0.584224 -0.153576      -1.086610\n",
       "urate        0.045754         0.839617 -0.095516      -2.782555\n",
       "age          0.162470         2.415161  0.227685       5.446676\n",
       "agesq       -0.002446        -3.025287 -0.003086      -6.333594\n",
       "schooling   -0.009235        -0.340397  0.089040       6.043669\n",
       "married      0.400315         2.134493  0.708420       6.175355\n",
       "famsize      0.062184         1.243172  0.062203       1.963769\n",
       "white        0.039181         0.221573  0.738064       7.069495\n",
       "excellent    2.918552         6.413353  3.703053      20.419854\n",
       "verygood     2.978532         6.475983  3.653558      19.507038\n",
       "good         2.494161         5.508672  2.999723      17.292446\n",
       "fair         1.460475         2.986829  1.876387      10.290242\n",
       "northeast    0.084304         0.349559  0.088733       0.592723\n",
       "midwest      0.015510         0.073955  0.122882       0.944832\n",
       "south        0.174893         0.840660  0.439300       3.449555\n",
       "center      -0.271525        -1.382293 -0.268835      -2.210969\n",
       "other       -0.091876        -0.472651  0.098020       0.782198\n",
       "firstq       0.422715         2.081702 -0.027288      -0.209837\n",
       "secondq     -0.021481        -0.100547 -0.110562      -0.868624\n",
       "thirdq      -0.036188        -0.166521 -0.052961      -0.412249\n",
       "const       -6.126585        -4.122494 -6.247362      -6.663820"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab = pd.DataFrame({\n",
    "    'Unemployed': thetahat[:,0], '(t, unemployed)': t[:,0],\n",
    "    'Employed':   thetahat[:,1], '(t, employed)':   t[:,1]\n",
    "},index=x_lab)\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the norm of the gradient, you can reuse the function defined above, but you need to redefine the anonymus function q yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q(thetahat)          =   0.3276\n",
      "2-norm of gradient   =  1.267e-07\n",
      "inf-norm of gradient =  6.886e-05\n"
     ]
    }
   ],
   "source": [
    "q = lambda theta: 1/N * np.sum(mlogit.q(theta, y, x))\n",
    "g = estimation.centered_grad(q, mlogit_result[\"theta\"]) # gradient at parameter estimates \n",
    "print(f'q(thetahat)          = {q(mlogit_result[\"theta\"]): 8.4g}')\n",
    "print(f'2-norm of gradient   = {np.mean(g ** 2): 8.4g}')\n",
    "print(f'inf-norm of gradient = {np.mean(np.abs(g)): 8.4g}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: Odds Ratio\n",
    "\n",
    "Consider a particular individual represented by\n",
    "the row vector of covariates\n",
    "$x_0 = (0, 6, 40, 40^2, 8, 0, 2, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1)$\n",
    "where the first element indicates that the individual does not abuse\n",
    "alcohol ($x_0[1]= 0$). Note that to facilitate convergence we need to\n",
    "again rescale some of the covariates. Following the rescale proposed in\n",
    "the expost code, the vector of covariates will become\n",
    "$x_0 = (0, 0.6, 4, 1.6, 0.8, 0, 2, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1)$.\n",
    "\n",
    "The odds ratio measures the probability of a given outcome to\n",
    "occur relative to the probability of a baseline outcome, conditional on\n",
    "the covariates. It is defined as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\Pr(y_i=j|\\mathbf{x}_i)}{\\Pr(y_i=1|\\mathbf{x}_i)} = \\frac{\\frac{\\exp \\{ \\mathbf{x}_{i}\\boldsymbol{\\beta}_j \\}}{ \\sum_{l=1}^J \\exp \\{ \\mathbf{x}_{i}\\boldsymbol{\\beta}_l \\}}}   {\\frac{\\exp \\{ \\mathbf{x}_{i}\\boldsymbol{\\beta}_1 \\}}{ \\sum_{l=1}^J \\exp \\{ \\mathbf{x}_{i}\\boldsymbol{\\beta}_l \\}}} = \\exp\\{\\mathbf{x}_i \\boldsymbol{\\beta}_j\\}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The odds ratio of being employed is therefore calculated as\n",
    "$x_0\\beta_3$, where $\\beta_3$ is the vector of parameters\n",
    "estimated for the third outcome (being employed).\n",
    "\n",
    "- Calculate the odds ratio of being unemployed (should be around `0.593`).\n",
    "- Calculate the odds ratio of being employed  (should be around `5.742`).\n",
    "\n",
    "How do we interpret these odds ratios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider some person\n",
    "x0 = np.array([[0., 6., 40., 40.*40., 8, 0, 2, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1]]).reshape(1, K)\n",
    "\n",
    "x1 = x0.copy()\n",
    "i_alco = 0 # variable corresponding to alcohol\n",
    "x1[0, i_alco] = 1.0 # sets alcohol abuse := 1 \n",
    "thetahat = mlogit_result['theta'].reshape(K, J-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fictitious individual, \"x0\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urate</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agesq</th>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schooling</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>married</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsize</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verygood</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fair</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>northeast</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>midwest</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>south</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>center</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firstq</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secondq</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thirdq</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fictitious individual, \"x0\"\n",
       "alcohol                            0.0\n",
       "urate                              6.0\n",
       "age                               40.0\n",
       "agesq                           1600.0\n",
       "schooling                          8.0\n",
       "married                            0.0\n",
       "famsize                            2.0\n",
       "white                              1.0\n",
       "excellent                          0.0\n",
       "verygood                           0.0\n",
       "good                               1.0\n",
       "fair                               0.0\n",
       "northeast                          0.0\n",
       "midwest                            1.0\n",
       "south                              0.0\n",
       "center                             1.0\n",
       "other                              0.0\n",
       "firstq                             1.0\n",
       "secondq                            0.0\n",
       "thirdq                             0.0\n",
       "const                              1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x0, columns=x_lab, index=['Fictitious individual, \"x0\"']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.597\n",
      "5.761\n"
     ]
    }
   ],
   "source": [
    "# odds ratio of being unemployed/employed vs being out of labor force\n",
    "odds_unemp = np.exp(x0 @ thetahat[:, 0])\n",
    "odds_emp   = np.exp(x0 @ thetahat[:, 1])\n",
    "print(f'{odds_unemp[0]:.3f}')\n",
    "print(f'{odds_emp[0]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6: Marginal Effects (discrete case)\n",
    "\n",
    "The marginal effect of a change in a binary covariate is computed by\n",
    "subtracting the conditional choice probability under the two possible\n",
    "values of the binary covariate $k$ (with and without alcohol\n",
    "abuse): \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta^d_j(x_{ik})=Pr(y_i=j|x_{ik}=1)-Pr(y_i=j|x_{ik}=0)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- Calculate the choice probability for person $x0$.\n",
    "- Calculate the choice probability for the same person but now with alcohol abuse set to 1 (`k=0`).\n",
    "- Subtract the choice probabilty of x1 from x0.\n",
    "- You should get values close to `[ 0.0154  0.0211  -0.0365]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marg_effect_discrete(betahat, x0, x1):\n",
    "    # Calculate the probabilities of x1 and x0, using betahat of the lates model estimation.\n",
    "    # Then substract the probability vector of x0 from the probability vector of x1.\n",
    "    prob_x1, _ = mlogit.choice_prob(betahat, x1)\n",
    "    prob_x0, _ = mlogit.choice_prob(betahat, x0)\n",
    "    return (prob_x1 - prob_x0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marginal effect (alcohol)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Out of labor force</th>\n",
       "      <td>0.0152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unemployed</th>\n",
       "      <td>0.0213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employed</th>\n",
       "      <td>-0.0364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Marginal effect (alcohol)\n",
       "Out of labor force                     0.0152\n",
       "Unemployed                             0.0213\n",
       "Employed                              -0.0364"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_alc = marg_effect_discrete(mlogit_result['theta'], x0, x1)\n",
    "\n",
    "tab = pd.DataFrame({'Marginal effect (alcohol)': me_alc}, index=y_values_lab).round(4)\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected results: \n",
    "\n",
    "|                    |   Marginal effect (alcohol) |\n",
    "|:-------------------|----------------------------:|\n",
    "| Out of labor force |                      0.0152 |\n",
    "| Unemployed         |                      0.0213 |\n",
    "| Employed           |                     -0.0364 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7: Marginal Effects (continuous case)\n",
    "\n",
    "- Calculate the marginal effect of education (`schooling`, with `k=4`) using the above equation. $\\beta_{jk}$ is given to you.\n",
    "- You should get values close to `[-0.00940 -0.00632  0.0157]`\n",
    "\n",
    "The marginal effect for the multinomial logit model with respect to a\n",
    "continuous covariate $k$ (e.g., schooling) is:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\Pr(y_i=j\\mid x_i)}{\\partial x_{ik}} = p_{ij} \\left(\\beta_{jk} - \\sum_{l=1}^J p_{il}\\beta_{lk}\\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We can calculate the full vector of marginal effects, \n",
    "$(  \\frac{\\partial \\Pr(y_i=0\\mid x_i)}{\\partial x_{ik}}, \n",
    "    \\frac{\\partial \\Pr(y_i=1\\mid x_i)}{\\partial x_{ik}}, \n",
    "    \\frac{\\partial \\Pr(y_i=2\\mid x_i)}{\\partial x_{ik}}\n",
    ")$, by using vector notation: \n",
    "$$\n",
    "\\frac{\\partial\\mathbf{p}_{i}}{\\partial x_{ik}}=\\mathbf{p}_{i}\\left(\\boldsymbol{\\beta}_{k}-\\sum_{l=1}^{J}p_{il}\\beta_{lk}\\right),\n",
    "$$ where $\\mathbf{p}_i$ is the $3 \\times 1$ vector $(p_{i0}, p_{i1}, p_{i2})$, and (in an unforgivable abuse of notation) $ \\boldsymbol{\\beta}_k = (\\beta_{0k}, \\beta_{1k}, \\beta_{2k})$ (a $J$-vector). Thus, the sum $\\sum_l p_{il} \\beta_{lk}$ can be written as the inner \"dot\" product of $\\mathbf{p}_i$ and $\\boldsymbol{\\beta}_k$. (And the coefficient for alcohold is $k = 4$ (in base 0).) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marg_effect_continuous(thetahat, theta_k, x):\n",
    "    N,K = x.shape\n",
    "    K,J_1 = thetahat.shape\n",
    "    J = J_1 + 1 # only coefficients for J-1 alternatives \n",
    "    \n",
    "    # 0. input checks \n",
    "    assert theta_k.ndim     == 2, f'\"theta_k\" should not be flattened (ndim==2 required)'\n",
    "    assert theta_k.shape[0] == J, f'\"theta_k\" should be {J=}, but got {theta_k.shape[0]}'\n",
    "    assert theta_k.shape[1] == 1, f'\"theta_k\" must be a column J-vector'\n",
    "    \n",
    "    # 1. compute derivative: return flattened (N*J, )\n",
    "    prob, _ = mlogit.choice_prob(thetahat, x) \n",
    "    p_bet = prob @ theta_k\n",
    "    diff = theta_k - p_bet\n",
    "    prob_diff = prob.T * diff # elementwise product\n",
    "    return (prob_diff).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marginal effect (education)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Out of labor force</th>\n",
       "      <td>-0.009374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unemployed</th>\n",
       "      <td>-0.006341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employed</th>\n",
       "      <td>0.015715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Marginal effect (education)\n",
       "Out of labor force                    -0.009374\n",
       "Unemployed                            -0.006341\n",
       "Employed                               0.015715"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetahat_educ = np.hstack([0.0, thetahat[4, :]]).reshape(J,1)\n",
    "me_educ = marg_effect_continuous(thetahat, thetahat_educ, x0)\n",
    "\n",
    "tab = pd.DataFrame({'Marginal effect (education)': me_educ}, index=y_values_lab).round(6)\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing our derivative with a numerical derivative\n",
    "To test our results, we can also simply compute a finite difference partial effect wrt. the $k$'th entry in `x0`. To do so, we want to use the simple standard formula for a numerical derivative \n",
    "$$ f'(x) \\cong \\frac{f((1+h)x)-f(x)}{hx}, \\quad \\text{for }h \\text{ small.} $$\n",
    "However, the function `mlogit.choice_prob` takes several inputs, and they are in vector form, so we write a small \"wrapper function\" that takes only a *scalar* as input, `x_k`, and fixes the remaining values and calls `mlogit.choice_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00937427 -0.00634097  0.01571524]]\n",
      "[[-7.49941720e-10 -5.07277359e-10  1.25721911e-09]]\n"
     ]
    }
   ],
   "source": [
    "# numerical partial derivative  \n",
    "k = 4\n",
    "def f(x_k): \n",
    "    '''choice_prob_handle: Function handle taking *scalar* inputs (for doing a numerical first difference)'''\n",
    "    assert np.isscalar(x_k), 'This function is defined for scalar values'\n",
    "    # x0 comes from \"global\" memory scope (set outside this function)\n",
    "    x0_ = np.copy(x0).astype(float) # we take a copy to avoid overwriting x0 (in python, you can write to inputs)\n",
    "    x0_[:,k] = x_k \n",
    "    prob, _ = mlogit.choice_prob(thetahat, x0_)\n",
    "    return prob\n",
    "\n",
    "# compute numerical finite difference\n",
    "h = 1e-8\n",
    "x0_k = x0[0,k] # years of education in our x0 vector \n",
    "f0 = f(x0_k)        # base\n",
    "f1 = f(x0_k*(1+h))  # forward step \n",
    "me_educ_num = (f1 - f0) / (h*x0_k)   # newton quotient\n",
    "print(me_educ_num) # verify that this gives the same numbers\n",
    "print(f1-f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping to get standard errors of marginal effects.\n",
    "\n",
    "Since we are not able to directly calculate variances for the marginal effects, we can use bootstrapping instead. This is done by taking a sample of our data, but with replacement. This means that we create a new data set as a random draw form our original data set, but we allow that the same observation is drawn multiple times. This new data set has the same number of observations as the original, but will differ sligthly since we now (may) have some duplicates.\n",
    "\n",
    "The procedure works as follows: \n",
    "* For each bootstrap iteration do: \n",
    "    1. Draw bootstrap sample (with replacement) \n",
    "    2. Estimate $\\hat{\\theta}$\n",
    "    3. Compute marginal effects using 1-2. \n",
    "\n",
    "We do this for many bootstrap iterations and then calculate the empirical standard deviation of the stored marginal effects over bootstrap iterations. This standard deviation is what we will use as our estimate of the *standard error* of the marginal effects. \n",
    "\n",
    "Do this in 4 steps: \n",
    "1. Write a function that, for a given dataset, `y`,`x`, runs estimation and computes marginal effects (2, 3). \n",
    "2. Write a function that draws a bootstrap sample with replacement from the original dataset. \n",
    "3. Run the bootstrap procedure. \n",
    "4. Print results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Estimating and computing marginal effects in one go\n",
    "\n",
    "First, we write a function that does everything we did above, given an input dataset, `y`, `x`\n",
    "1. Estimate parameters, \n",
    "2. Compute marginal effect for alcohol (discrete) \n",
    "3. Compute marginal effect for education (continuous)\n",
    "    - Construct the $J$-sub-vector of education betas (adding the normalized $\\theta_{40}=0$ in front)\n",
    "    - Compute marginal effect using the analytic formula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_and_compute_marg_effs(y, x, x0, x1, theta_start, disp=False): \n",
    "    '''Estimate and compute marginal effects\n",
    "    Args. \n",
    "        y: N-vector of discrete outcomes\n",
    "        x: N*J matrix of explanatory variables\n",
    "        x0: K-vector of explanatory variables \n",
    "        x1: K-vector, alcohol switched on \n",
    "        \n",
    "    Returns\n",
    "        tuple of floats: \n",
    "            me_alco: marginal effect wrt. alcohol (discrete)\n",
    "            me_educ: marginal effect wrt. education (continuous)\n",
    "    '''\n",
    "    assert y.ndim == 1 , 'y must be a flattened array'\n",
    "    assert x.ndim == 2 , 'x must be 2-dimensional'\n",
    "    assert theta_start.ndim == 2, 'theta_start should be 2-dimensional'\n",
    "    assert theta_start.shape[0] == x.shape[1], 'theta_start and x should conform'\n",
    "    \n",
    "    N,K = x.shape\n",
    "    _,J_1 = theta_start.shape \n",
    "    J = J_1 + 1 \n",
    "    \n",
    "    # 1. estimate \n",
    "    res = estimation.estimate(mlogit.q, theta_start, y, x, options={'disp':disp})\n",
    "    betahat = res['theta'].reshape(K,J-1)\n",
    "    \n",
    "    # 2. marginal effect of alcohol \n",
    "    me_alco = marg_effect_discrete(betahat, x0, x1)\n",
    "    \n",
    "    # 3. marginal effect of education \n",
    "    # 3.a sub-vector of parameters \n",
    "    bet_educ = np.hstack([0.0, betahat[4,:]]).reshape((J,1))\n",
    "    # 3.b marg. effect\n",
    "    me_educ = marg_effect_continuous(betahat, bet_educ, x0)\n",
    "    \n",
    "    # 4. return \n",
    "    return me_alco, me_educ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the function for our baseline dataset and note how long it takes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alco: [ 0.0152  0.0213 -0.0364]\n",
      "Educ: [-0.0094 -0.0063  0.0157]\n",
      "CPU times: total: 250 ms\n",
      "Wall time: 188 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "me_alco, me_educ = estimate_and_compute_marg_effs(y,x,x0,x1,theta_start=thetahat)\n",
    "print(f'Alco: {me_alco.round(4)}')\n",
    "print(f'Educ: {me_educ.round(4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Function to draw a bootstrap sample\n",
    "\n",
    "The function should draw *indices* for the observations (rows) to be drawn. \n",
    "* *Hint:* Look at the function `np.random.choice(Nmax, Nsamples, replace = True)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample(y,x): \n",
    "    '''bootstrap_sample: samples a new dataset (with replacement) from the input. \n",
    "    Args. \n",
    "        y: 1-dimensional N-array\n",
    "        x: (N,K) matrix \n",
    "    Returns\n",
    "        tuple: y_i, x_i \n",
    "            y_i: N-array\n",
    "            x_i: (N,K) matrix \n",
    "    '''\n",
    "    N = y.size\n",
    "    \n",
    "    ii_boot = np.random.choice(N, N, replace=True) # vector of indices for rows \n",
    "    y_i = y[ii_boot]\n",
    "    x_i = x[ii_boot] \n",
    "    \n",
    "    return y_i, x_i "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Run the bootstrap procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap iteration 1/10\n",
      "Bootstrap iteration 2/10\n",
      "Bootstrap iteration 3/10\n",
      "Bootstrap iteration 4/10\n",
      "Bootstrap iteration 5/10\n",
      "Bootstrap iteration 6/10\n",
      "Bootstrap iteration 7/10\n",
      "Bootstrap iteration 8/10\n",
      "Bootstrap iteration 9/10\n",
      "Bootstrap iteration 10/10\n"
     ]
    }
   ],
   "source": [
    "nboot = 10  # Number of bootstraps, should ideally be very large \n",
    "\n",
    "# Set seed for random sampling.\n",
    "seed = 42\n",
    "rng = default_rng()\n",
    "\n",
    "# initialize \n",
    "me_alco = np.empty((nboot,J))\n",
    "me_educ = np.empty((nboot,J))\n",
    "\n",
    "for i in range(nboot): \n",
    "    print(f'Bootstrap iteration {i+1}/{nboot}')\n",
    "    \n",
    "    # 1. choose which individuals to draw\n",
    "    y_i, x_i = bootstrap_sample(y,x)\n",
    "    \n",
    "    # 2. estimate and compute \n",
    "    ma, me = estimate_and_compute_marg_effs(y_i, x_i, x0, x1, theta_start=thetahat)\n",
    "    me_alco[i,:] = ma\n",
    "    me_educ[i,:] = me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Show the results \n",
    "\n",
    "***Note:*** For results to believable in practice, the number of bootstrap repititions needs to be quite high, over 100 and preferably 1000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJe0lEQVR4nO3deXxM9/4/8NckkclCJoRsZKNEkcXSpLGU1pCkitwuSHuJWKvUEkpzvxWU26CtrVVKEXpVrKWlN5ZoqAixxRqRRAiVxJZFgoTk8/vDz7mdZh1msjiv5+NxHu35nM/5zPucSXj5nHNmFEIIASIiIiIZMajpAoiIiIiqGwMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJjlFNF1AblZSU4MaNG2jQoAEUCkVNl0NERERVIITAvXv3YG9vDwODiud4GIDKcOPGDTg4ONR0GURERPQMrl27hmbNmlXYhwGoDA0aNADw5ARaWFjUcDVERERUFXl5eXBwcJD+Hq8IA1AZnl72srCwYAAiIiKqY6py+wpvgiYiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2anRABQeHo5XXnkFDRo0gLW1NQICApCUlFTpfps3b0br1q1hYmICNzc3/PbbbxrbhRAICwuDnZ0dTE1NoVarkZycrK/DICIiojqmRgPQgQMHMHbsWBw5cgR79+7Fo0eP0Lt3bxQUFJS7z+HDhxEYGIjhw4fj1KlTCAgIQEBAAM6dOyf1mT9/PpYsWYLly5fj6NGjMDc3h6+vLx4+fFgdh0VERES1nEIIIWq6iKdu3boFa2trHDhwAK+99lqZfQYOHIiCggLs3LlTanv11Vfh6emJ5cuXQwgBe3t7TJ48GVOmTAEA5ObmwsbGBhERERg0aFCldeTl5UGlUiE3N5ffBk9ERFRHaPP3d626Byg3NxcA0KhRo3L7xMXFQa1Wa7T5+voiLi4OAJCWlobMzEyNPiqVCt7e3lKfvyssLEReXp7GQkRERC8uo5ou4KmSkhJMnDgRXbp0Qbt27crtl5mZCRsbG402GxsbZGZmStuftpXX5+/Cw8Mxa9as5ylfK86f7nrmfa/M7aPDSoiIiOSp1swAjR07FufOnUNkZGS1v3ZoaChyc3Ol5dq1a9VeAxEREVWfWjEDNG7cOOzcuRMHDx5Es2bNKuxra2uLrKwsjbasrCzY2tpK25+22dnZafTx9PQsc0ylUgmlUvkcR0BERER1SY3OAAkhMG7cOPz888/Yv38/XFxcKt3Hx8cH0dHRGm179+6Fj48PAMDFxQW2trYaffLy8nD06FGpDxEREclbjc4AjR07Fj/99BN27NiBBg0aSPfoqFQqmJqaAgCGDBmCpk2bIjw8HAAwYcIEdO/eHV9//TX69OmDyMhIHD9+HCtWrAAAKBQKTJw4EXPmzEHLli3h4uKC6dOnw97eHgEBATVynERERFS71GgAWrZsGQCgR48eGu1r1qzB0KFDAQDp6ekwMPjfRFXnzp3x008/4bPPPsO//vUvtGzZEtu3b9e4cXrq1KkoKCjAqFGjkJOTg65duyIqKgomJiZ6PyYiIiKq/WrV5wDVFvr+HCA+BUZERKR7dfZzgIiIiIiqAwMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREclOjQaggwcPom/fvrC3t4dCocD27dsr7D906FAoFIpSS9u2baU+M2fOLLW9devWej4SIiIiqktqNAAVFBTAw8MDS5curVL/xYsXIyMjQ1quXbuGRo0a4b333tPo17ZtW41+hw4d0kf5REREVEcZ1eSL+/v7w9/fv8r9VSoVVCqVtL59+3ZkZ2cjODhYo5+RkRFsbW11VicRERG9WOr0PUCrVq2CWq2Gk5OTRntycjLs7e3RvHlzfPDBB0hPT69wnMLCQuTl5WksRERE9OKqswHoxo0b+O9//4sRI0ZotHt7eyMiIgJRUVFYtmwZ0tLS0K1bN9y7d6/cscLDw6XZJZVKBQcHB32XT0RERDWozgagtWvXwtLSEgEBARrt/v7+eO+99+Du7g5fX1/89ttvyMnJwaZNm8odKzQ0FLm5udJy7do1PVdPRERENalG7wF6VkIIrF69GoMHD4axsXGFfS0tLdGqVSukpKSU20epVEKpVOq6TCIiIqql6uQM0IEDB5CSkoLhw4dX2jc/Px+pqamws7OrhsqIiIioLqjRAJSfn4+EhAQkJCQAANLS0pCQkCDdtBwaGoohQ4aU2m/VqlXw9vZGu3btSm2bMmUKDhw4gCtXruDw4cP4xz/+AUNDQwQGBur1WIiIiKjuqNFLYMePH8frr78urYeEhAAAgoKCEBERgYyMjFJPcOXm5mLr1q1YvHhxmWNev34dgYGBuHPnDpo0aYKuXbviyJEjaNKkif4OhIiIiOoUhRBC1HQRtU1eXh5UKhVyc3NhYWGh8/GdP931zPtemdtHh5UQERG9OLT5+7tO3gNERERE9DwYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdmo0AB08eBB9+/aFvb09FAoFtm/fXmH/mJgYKBSKUktmZqZGv6VLl8LZ2RkmJibw9vZGfHy8Ho+CiIiI6poaDUAFBQXw8PDA0qVLtdovKSkJGRkZ0mJtbS1t27hxI0JCQjBjxgycPHkSHh4e8PX1xc2bN3VdPhEREdVRRjX54v7+/vD399d6P2tra1haWpa5bcGCBRg5ciSCg4MBAMuXL8euXbuwevVqfPrpp89TLhEREb0g6uQ9QJ6enrCzs0OvXr0QGxsrtRcVFeHEiRNQq9VSm4GBAdRqNeLi4sodr7CwEHl5eRoLERERvbjqVACys7PD8uXLsXXrVmzduhUODg7o0aMHTp48CQC4ffs2iouLYWNjo7GfjY1NqfuE/io8PBwqlUpaHBwc9HocREREVLNq9BKYtlxdXeHq6iqtd+7cGampqVi4cCF+/PHHZx43NDQUISEh0npeXh5DEBER0QusTgWgsnh5eeHQoUMAgMaNG8PQ0BBZWVkafbKysmBra1vuGEqlEkqlUq91EhERUe1Rpy6BlSUhIQF2dnYAAGNjY3Ts2BHR0dHS9pKSEkRHR8PHx6emSiQiIqJapkZngPLz85GSkiKtp6WlISEhAY0aNYKjoyNCQ0Px559/Yt26dQCARYsWwcXFBW3btsXDhw/xww8/YP/+/dizZ480RkhICIKCgtCpUyd4eXlh0aJFKCgokJ4KIyIiIqrRAHT8+HG8/vrr0vrT+3CCgoIQERGBjIwMpKenS9uLioowefJk/PnnnzAzM4O7uzv27dunMcbAgQNx69YthIWFITMzE56enoiKiip1YzQRERHJl0IIIWq6iNomLy8PKpUKubm5sLCw0Pn4zp/ueuZ9r8zto8NKiIiIXhza/P1d5+8BIiIiItIWAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyc5zB6C8vDxs374diYmJuqiHiIiISO+0DkADBgzAt99+CwB48OABOnXqhAEDBsDd3R1bt27VeYFEREREuqZ1ADp48CC6desGAPj5558hhEBOTg6WLFmCOXPm6LxAIiIiIl3TOgDl5uaiUaNGAICoqCi88847MDMzQ58+fZCcnKzzAomIiIh0TesA5ODggLi4OBQUFCAqKgq9e/cGAGRnZ8PExETnBRIRERHpmpG2O0ycOBEffPAB6tevD0dHR/To0QPAk0tjbm5uuq6PiIiISOe0DkAfffQRvLy8cO3aNfTq1QsGBk8mkZo3b857gIiIiKhO0DoAAUCnTp3g7u6OtLQ0tGjRAkZGRujTp4+uayMiIiLSC63vAbp//z6GDx8OMzMztG3bFunp6QCAjz/+GHPnztV5gURERES6pnUACg0NxenTpxETE6Nx07NarcbGjRt1WhwRERGRPmh9CWz79u3YuHEjXn31VSgUCqm9bdu2SE1N1WlxRERERPqg9QzQrVu3YG1tXaq9oKBAIxARERER1VZaB6BOnTph165d0vrT0PPDDz/Ax8dHd5URERER6YnWl8C++OIL+Pv748KFC3j8+DEWL16MCxcu4PDhwzhw4IA+aiQiIiLSKa1ngLp27YqEhAQ8fvwYbm5u2LNnD6ytrREXF4eOHTvqo0YiIiIinXqmzwFq0aIFVq5cqetaiIiIiKpFlQJQXl5elQe0sLB45mKIiIiIqkOVApClpWWlT3gJIaBQKFBcXKyTwoiIiIj0pUoB6Pfff9d3HURERETVpkoBqHv37vqug4iIiKjaPNNN0NnZ2Vi1ahUSExMBAG3atEFwcDAaNWqk0+KIiIiI9EHrx+APHjwIZ2dnLFmyBNnZ2cjOzsaSJUvg4uKCgwcP6qNGIiIiIp3SegZo7NixGDhwIJYtWwZDQ0MAQHFxMT766COMHTsWZ8+e1XmRRERERLqk9QxQSkoKJk+eLIUfADA0NERISAhSUlJ0WhwRERGRPmgdgDp06CDd+/NXiYmJ8PDw0GqsgwcPom/fvrC3t4dCocD27dsr7L9t2zb06tULTZo0gYWFBXx8fLB7926NPjNnzoRCodBYWrdurVVdRERE9GLT+hLY+PHjMWHCBKSkpODVV18FABw5cgRLly7F3LlzcebMGamvu7t7hWMVFBTAw8MDw4YNw9tvv13pax88eBC9evXCF198AUtLS6xZswZ9+/bF0aNH0b59e6lf27ZtsW/fvv8dpNEz3etNRERELyitk0FgYCAAYOrUqWVuUygUVf5QRH9/f/j7+1f5tRctWqSx/sUXX2DHjh349ddfNQKQkZERbG1tqzwuERERyYvWASgtLU0fdTyTkpIS3Lt3r9Tj98nJybC3t4eJiQl8fHwQHh4OR0fHcscpLCxEYWGhtK7NV38QERFR3aN1AHJyctJHHc/kq6++Qn5+PgYMGCC1eXt7IyIiAq6ursjIyMCsWbPQrVs3nDt3Dg0aNChznPDwcMyaNau6yiYiIqIa9kw3x9y4cQOHDh3CzZs3UVJSorFt/PjxOimsMj/99BNmzZqFHTt2wNraWmr/6yU1d3d3eHt7w8nJCZs2bcLw4cPLHCs0NBQhISHSel5eHhwcHPRXPBEREdUorQNQREQERo8eDWNjY1hZWWl8SapCoaiWABQZGYkRI0Zg8+bNUKvVFfa1tLREq1atKnxEX6lUQqlU6rpMIiIiqqW0fgx++vTpCAsLQ25uLq5cuYK0tDRpuXz5sj5q1LBhwwYEBwdjw4YN6NOnT6X98/PzkZqaCjs7O73XRkRERHWD1jNA9+/fx6BBg2BgoHV2KiU/P19jZiYtLQ0JCQlo1KgRHB0dERoaij///BPr1q0D8OSyV1BQEBYvXgxvb29kZmYCAExNTaFSqQAAU6ZMQd++feHk5IQbN25gxowZMDQ0lJ5eIyIiItI6xQwfPhybN2/WyYsfP34c7du3lx5hDwkJQfv27REWFgYAyMjIQHp6utR/xYoVePz4McaOHQs7OztpmTBhgtTn+vXrCAwMhKurKwYMGAArKyscOXIETZo00UnNREREVPcphBBCmx2Ki4vx1ltv4cGDB3Bzc0O9evU0ti9YsECnBdaEvLw8qFQq5ObmwsLCQufjO3+665n3vTK38st+REREcqTN399aXwILDw/H7t274erqCgClboImIiIiqu20DkBff/01Vq9ejaFDh+qhHCIiIiL90/oeIKVSiS5duuijFiIiIqJqoXUAmjBhAr755ht91EJERERULbS+BBYfH4/9+/dj586daNu2bamboLdt26az4oiIiIj0QesAZGlpibffflsftRARERFVC60D0Jo1a/RRBxEREVG1ef6PcyYiIiKqY57p2+C3bNmCTZs2IT09HUVFRRrbTp48qZPCiIiIiPRF6xmgJUuWIDg4GDY2Njh16hS8vLxgZWWFy5cvw9/fXx81EhEREemU1gHou+++w4oVK/DNN9/A2NgYU6dOxd69ezF+/Hjk5ubqo0YiIiIindI6AKWnp6Nz584AnnwL+7179wAAgwcPxoYNG3RbHREREZEeaB2AbG1tcffuXQCAo6Mjjhw5AgBIS0uDlt+rSkRERFQjtA5Ab7zxBn755RcAQHBwMCZNmoRevXph4MCB+Mc//qHzAomIiIh0TeunwFasWIGSkhIAwNixY2FlZYXDhw+jX79+GD16tM4LJCIiItI1rQOQgYEBDAz+N3E0aNAgDBo0SKdFEREREemT1pfAoqKicOjQIWl96dKl8PT0xPvvv4/s7GydFkdERESkD1oHoE8++QR5eXkAgLNnzyIkJARvvvkm0tLSEBISovMCiYiIiHRN60tgaWlpaNOmDQBg69at6Nu3L7744gucPHkSb775ps4LJCIiItI1rWeAjI2Ncf/+fQDAvn370Lt3bwBAo0aNpJkhIiIiotpM6xmgrl27IiQkBF26dEF8fDw2btwIALh06RKaNWum8wKJiIiIdE3rGaBvv/0WRkZG2LJlC5YtW4amTZsCAP773//Cz89P5wUSERER6ZrWM0COjo7YuXNnqfaFCxfqpCAiIiIifdN6BoiIiIiormMAIiIiItlhACIiIiLZYQAiIiIi2XmuAHTt2jVcu3ZNV7UQERERVQutA9Djx48xffp0qFQqODs7w9nZGSqVCp999hkePXqkjxqJiIiIdErrx+A//vhjbNu2DfPnz4ePjw8AIC4uDjNnzsSdO3ewbNkynRdJREREpEtaB6CffvoJkZGR8Pf3l9rc3d3h4OCAwMBABiAiIiKq9bS+BKZUKuHs7Fyq3cXFBcbGxrqoiYiIiEivtA5A48aNw+zZs1FYWCi1FRYW4t///jfGjRun0+KIiIiI9EHrAHTq1Cns3LkTzZo1g1qthlqtRrNmzfDrr7/i9OnTePvtt6WlMgcPHkTfvn1hb28PhUKB7du3V7pPTEwMOnToAKVSiZdeegkRERGl+ixduhTOzs4wMTGBt7c34uPjtT1MIiIieoFpfQ+QpaUl3nnnHY02BweHZ3rxgoICeHh4YNiwYVUKTGlpaejTpw8+/PBDrF+/HtHR0RgxYgTs7Ozg6+sLANi4cSNCQkKwfPlyeHt7Y9GiRfD19UVSUhKsra2fqU4iIiJ6sSiEEKKmiwAAhUKBn3/+GQEBAeX2mTZtGnbt2oVz585JbYMGDUJOTg6ioqIAAN7e3njllVfw7bffAgBKSkrg4OCAjz/+GJ9++mmVasnLy4NKpUJubi4sLCye/aDK4fzprmfe98rcPjqshIiI6MWhzd/fdeqToOPi4qBWqzXafH19ERcXBwAoKirCiRMnNPoYGBhArVZLfcpSWFiIvLw8jYWIiIheXFpfAgOALVu2YNOmTUhPT0dRUZHGtpMnT+qksLJkZmbCxsZGo83GxgZ5eXl48OABsrOzUVxcXGafixcvljtueHg4Zs2apZeada2mZo84a1V1z3OunkdNnee6+LMht/eISB/q4u/+X2k9A7RkyRIEBwfDxsYGp06dgpeXF6ysrHD58mWNzwaqS0JDQ5Gbmyst/HoPIiKiF5vWM0DfffcdVqxYgcDAQERERGDq1Klo3rw5wsLCcPfuXX3UKLG1tUVWVpZGW1ZWFiwsLGBqagpDQ0MYGhqW2cfW1rbccZVKJZRKpV5qJiIiotpH6xmg9PR0dO7cGQBgamqKe/fuAQAGDx6MDRs26La6v/Hx8UF0dLRG2969e6Wv5DA2NkbHjh01+pSUlCA6OlrqQ0RERKR1ALK1tZVmehwdHXHkyBEATx5R1/aBsvz8fCQkJCAhIUEaIyEhAenp6QCeXJoaMmSI1P/DDz/E5cuXMXXqVFy8eBHfffcdNm3ahEmTJkl9QkJCsHLlSqxduxaJiYkYM2YMCgoKEBwcrO2hEhER0QtK60tgb7zxBn755Re0b98ewcHBmDRpErZs2YLjx49X6bN8/ur48eN4/fXXpfWQkBAAQFBQECIiIpCRkSGFIeDJ123s2rULkyZNwuLFi9GsWTP88MMP0mcAAcDAgQNx69YthIWFITMzE56enoiKiip1YzQRERHJl9YBaMWKFSgpKQEAjB07FlZWVjh8+DD69euH0aNHazVWjx49Kpw1KutTnnv06IFTp05VOO64ceP4tRxERERULq0C0OPHj/HFF19g2LBhaNasGYAnH0Q4aNAgvRRHREREpA9a3QNkZGSE+fPn4/Hjx/qqh4iIiEjvtL4JumfPnjhw4IA+aiEiIiKqFlrfA+Tv749PP/0UZ8+eRceOHWFubq6xvV+/fjorjoiIiEgftA5AH330EQBgwYIFpbYpFAoUFxc/f1VEREREeqR1AHr6BBgRERFRXaX1PUDr1q1DYWFhqfaioiKsW7dOJ0URERER6ZPWASg4OBi5ubml2u/du8dPWyYiIqI6QesAJISAQqEo1X79+nWoVCqdFEVERESkT1W+B6h9+/ZQKBRQKBTo2bMnjIz+t2txcTHS0tLg5+enlyKJiIiIdKnKASggIAAAkJCQAF9fX9SvX1/aZmxsDGdnZ7zzzjs6L5CIiIhI16ocgGbMmAEAcHZ2xqBBg6BUKvVWFBEREZE+aX0P0BtvvIFbt25J6/Hx8Zg4cSJWrFih08KIiIiI9EXrAPT+++/j999/BwBkZmZCrVYjPj4e//d//4fPP/9c5wUSERER6ZrWAejcuXPw8vICAGzatAlubm44fPgw1q9fj4iICF3XR0RERKRzWgegR48eSff/7Nu3T/rur9atWyMjI0O31RERERHpgdYBqG3btli+fDn++OMP7N27V3r0/caNG7CystJ5gURERES6pnUAmjdvHr7//nv06NEDgYGB8PDwAAD88ssv0qUxIiIiotpM6y9D7dGjB27fvo28vDw0bNhQah81ahTMzc11WhwRERGRPjzTY/D37t3TCD8A0KhRIwwcOFBnhRERERHpi9YBKCYmBkVFRaXaHz58iD/++EMnRRERERHpU5UvgZ05c0b6/wsXLiAzM1NaLy4uRlRUFJo2barb6oiIiIj0oMoByNPTU/oy1DfeeKPUdlNTU3zzzTc6LY6IiIhIH6ocgNLS0iCEQPPmzREfH48mTZpI24yNjWFtbQ1DQ0O9FElERESkS1UOQE5OTgCAkpISvRVDREREVB20fgweAFJTU7Fo0SIkJiYCANq0aYMJEyagRYsWOi2OiIiISB+0fgps9+7daNOmDeLj4+Hu7g53d3ccPXoUbdu2xd69e/VRIxEREZFOaT0D9Omnn2LSpEmYO3duqfZp06ahV69eOiuOiIiISB+0ngFKTEzE8OHDS7UPGzYMFy5c0ElRRERERPqkdQBq0qQJEhISSrUnJCTA2tpaFzURERER6ZXWl8BGjhyJUaNG4fLly+jcuTMAIDY2FvPmzUNISIjOCyQiIiLSNa0D0PTp09GgQQN8/fXXCA0NBQDY29tj5syZGD9+vM4LJCIiItI1rQOQQqHApEmTMGnSJNy7dw8A0KBBA50XRkRERKQvWt8D9NStW7dw+vRpnD59Grdv336uIpYuXQpnZ2eYmJjA29sb8fHx5fbt0aOH9JUcf1369Okj9Rk6dGip7X5+fs9VIxEREb04tA5ABQUFGDZsGOzs7PDaa6/htddeg52dHYYPH4779+9rXcDGjRsREhKCGTNm4OTJk/Dw8ICvry9u3rxZZv9t27YhIyNDWs6dOwdDQ0O89957Gv38/Pw0+m3YsEHr2oiIiOjFpHUACgkJwYEDB/Drr78iJycHOTk52LFjBw4cOIDJkydrXcCCBQswcuRIBAcHo02bNli+fDnMzMywevXqMvs3atQItra20rJ3716YmZmVCkBKpVKjX8OGDbWujYiIiF5MWgegrVu3YtWqVfD394eFhQUsLCzw5ptvYuXKldiyZYtWYxUVFeHEiRNQq9X/K8jAAGq1GnFxcVUaY9WqVRg0aBDMzc012mNiYmBtbQ1XV1eMGTMGd+7cKXeMwsJC5OXlaSxERET04tI6AN2/fx82Njal2q2trbW+BHb79m0UFxeXGs/GxgaZmZmV7h8fH49z585hxIgRGu1+fn5Yt24doqOjMW/ePBw4cAD+/v4oLi4uc5zw8HCoVCppcXBw0Oo4iIiIqG7ROgD5+PhgxowZePjwodT24MEDzJo1Cz4+PjotrjKrVq2Cm5sbvLy8NNoHDRqEfv36wc3NDQEBAdi5cyeOHTuGmJiYMscJDQ1Fbm6utFy7dq0aqiciIqKaovVj8IsXL4avry+aNWsGDw8PAMDp06dhYmKC3bt3azVW48aNYWhoiKysLI32rKws2NraVrhvQUEBIiMj8fnnn1f6Os2bN0fjxo2RkpKCnj17ltquVCqhVCq1qp2IiIjqLq1ngNq1a4fk5GSEh4fD09MTnp6emDt3LpKTk9G2bVutxjI2NkbHjh0RHR0ttZWUlCA6OrrS2aTNmzejsLAQ//znPyt9nevXr+POnTuws7PTqj4iIiJ6MWk9AwQAZmZmGDlypE4KCAkJQVBQEDp16gQvLy8sWrQIBQUFCA4OBgAMGTIETZs2RXh4uMZ+q1atQkBAAKysrDTa8/PzMWvWLLzzzjuwtbVFamoqpk6dipdeegm+vr46qZmIiIjqNq0D0J07d6TQce3aNaxcuRIPHjxA37598dprr2ldwMCBA3Hr1i2EhYUhMzMTnp6eiIqKkm6MTk9Ph4GB5kRVUlISDh06hD179pQaz9DQEGfOnMHatWuRk5MDe3t79O7dG7Nnz+ZlLiIiIgKgRQA6e/Ys+vbti2vXrqFly5aIjIyEn58fCgoKYGBggIULF2LLli0ICAjQuohx48Zh3LhxZW4r68ZlV1dXCCHK7G9qaqr1vUhEREQkL1W+B2jq1Klwc3PDwYMH0aNHD7z11lvo06cPcnNzkZ2djdGjR2Pu3Ln6rJWIiIhIJ6o8A3Ts2DHs378f7u7u8PDwwIoVK/DRRx9Jl6c+/vhjvPrqq3orlIiIiEhXqjwDdPfuXenR9Pr168Pc3Fzj6yUaNmwofTs8ERERUW2m1WPwCoWiwnUiIiKiukCrp8CGDh0qPUn18OFDfPjhh9J3cBUWFuq+OiIiIiI9qHIACgoK0lgv6wMIhwwZ8vwVEREREelZlQPQmjVr9FkHERERUbXR+qswiIiIiOo6BiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSnVoRgJYuXQpnZ2eYmJjA29sb8fHx5faNiIiAQqHQWExMTDT6CCEQFhYGOzs7mJqaQq1WIzk5Wd+HQURERHVEjQegjRs3IiQkBDNmzMDJkyfh4eEBX19f3Lx5s9x9LCwskJGRIS1Xr17V2D5//nwsWbIEy5cvx9GjR2Fubg5fX188fPhQ34dDREREdUCNB6AFCxZg5MiRCA4ORps2bbB8+XKYmZlh9erV5e6jUChga2srLTY2NtI2IQQWLVqEzz77DP3794e7uzvWrVuHGzduYPv27dVwRERERFTb1WgAKioqwokTJ6BWq6U2AwMDqNVqxMXFlbtffn4+nJyc4ODggP79++P8+fPStrS0NGRmZmqMqVKp4O3tXe6YhYWFyMvL01iIiIjoxVWjAej27dsoLi7WmMEBABsbG2RmZpa5j6urK1avXo0dO3bgP//5D0pKStC5c2dcv34dAKT9tBkzPDwcKpVKWhwcHJ730IiIiKgWq/FLYNry8fHBkCFD4Onpie7du2Pbtm1o0qQJvv/++2ceMzQ0FLm5udJy7do1HVZMREREtU2NBqDGjRvD0NAQWVlZGu1ZWVmwtbWt0hj16tVD+/btkZKSAgDSftqMqVQqYWFhobEQERHRi6tGA5CxsTE6duyI6Ohoqa2kpATR0dHw8fGp0hjFxcU4e/Ys7OzsAAAuLi6wtbXVGDMvLw9Hjx6t8phERET0YjOq6QJCQkIQFBSETp06wcvLC4sWLUJBQQGCg4MBAEOGDEHTpk0RHh4OAPj888/x6quv4qWXXkJOTg6+/PJLXL16FSNGjADw5AmxiRMnYs6cOWjZsiVcXFwwffp02NvbIyAgoKYOk4iIiGqRGg9AAwcOxK1btxAWFobMzEx4enoiKipKuok5PT0dBgb/m6jKzs7GyJEjkZmZiYYNG6Jjx444fPgw2rRpI/WZOnUqCgoKMGrUKOTk5KBr166Iiooq9YGJREREJE81HoAAYNy4cRg3blyZ22JiYjTWFy5ciIULF1Y4nkKhwOeff47PP/9cVyUSERHRC6TOPQVGRERE9LwYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdmpFAFq6dCmcnZ1hYmICb29vxMfHl9t35cqV6NatGxo2bIiGDRtCrVaX6j906FAoFAqNxc/PT9+HQURERHVEjQegjRs3IiQkBDNmzMDJkyfh4eEBX19f3Lx5s8z+MTExCAwMxO+//464uDg4ODigd+/e+PPPPzX6+fn5ISMjQ1o2bNhQHYdDREREdUCNB6AFCxZg5MiRCA4ORps2bbB8+XKYmZlh9erVZfZfv349PvroI3h6eqJ169b44YcfUFJSgujoaI1+SqUStra20tKwYcPqOBwiIiKqA2o0ABUVFeHEiRNQq9VSm4GBAdRqNeLi4qo0xv379/Ho0SM0atRIoz0mJgbW1tZwdXXFmDFjcOfOnXLHKCwsRF5ensZCREREL64aDUC3b99GcXExbGxsNNptbGyQmZlZpTGmTZsGe3t7jRDl5+eHdevWITo6GvPmzcOBAwfg7++P4uLiMscIDw+HSqWSFgcHh2c/KCIiIqr1jGq6gOcxd+5cREZGIiYmBiYmJlL7oEGDpP93c3ODu7s7WrRogZiYGPTs2bPUOKGhoQgJCZHW8/LyGIKIiIheYDU6A9S4cWMYGhoiKytLoz0rKwu2trYV7vvVV19h7ty52LNnD9zd3Svs27x5czRu3BgpKSllblcqlbCwsNBYiIiI6MVVowHI2NgYHTt21LiB+ekNzT4+PuXuN3/+fMyePRtRUVHo1KlTpa9z/fp13LlzB3Z2djqpm4iIiOq2Gn8KLCQkBCtXrsTatWuRmJiIMWPGoKCgAMHBwQCAIUOGIDQ0VOo/b948TJ8+HatXr4azszMyMzORmZmJ/Px8AEB+fj4++eQTHDlyBFeuXEF0dDT69++Pl156Cb6+vjVyjERERFS71Pg9QAMHDsStW7cQFhaGzMxMeHp6IioqSroxOj09HQYG/8tpy5YtQ1FREd59912NcWbMmIGZM2fC0NAQZ86cwdq1a5GTkwN7e3v07t0bs2fPhlKprNZjIyIiotqpxgMQAIwbNw7jxo0rc1tMTIzG+pUrVyocy9TUFLt379ZRZURERPQiqvFLYERERETVjQGIiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGSnVgSgpUuXwtnZGSYmJvD29kZ8fHyF/Tdv3ozWrVvDxMQEbm5u+O233zS2CyEQFhYGOzs7mJqaQq1WIzk5WZ+HQERERHVIjQegjRs3IiQkBDNmzMDJkyfh4eEBX19f3Lx5s8z+hw8fRmBgIIYPH45Tp04hICAAAQEBOHfunNRn/vz5WLJkCZYvX46jR4/C3Nwcvr6+ePjwYXUdFhEREdViNR6AFixYgJEjRyI4OBht2rTB8uXLYWZmhtWrV5fZf/HixfDz88Mnn3yCl19+GbNnz0aHDh3w7bffAngy+7No0SJ89tln6N+/P9zd3bFu3TrcuHED27dvr8YjIyIiotrKqCZfvKioCCdOnEBoaKjUZmBgALVajbi4uDL3iYuLQ0hIiEabr6+vFG7S0tKQmZkJtVotbVepVPD29kZcXBwGDRpUaszCwkIUFhZK67m5uQCAvLy8Zz62ipQU3tfLuJV5nuN5npr1dR5rq7r4/j6PuvizIbf3iEgfauPv/tNxhRCV9q3RAHT79m0UFxfDxsZGo93GxgYXL14sc5/MzMwy+2dmZkrbn7aV1+fvwsPDMWvWrFLtDg4OVTuQOkK1SF6vKzd18TzXxZqfh9yOl6g8+v5duHfvHlQqVYV9ajQA1RahoaEas0olJSW4e/curKysoFAoarCyqsvLy4ODgwOuXbsGCwuLmi7nhcHzqns8p/rB86ofPK+6p89zKoTAvXv3YG9vX2nfGg1AjRs3hqGhIbKysjTas7KyYGtrW+Y+tra2FfZ/+t+srCzY2dlp9PH09CxzTKVSCaVSqdFmaWmpzaHUGhYWFvwl1QOeV93jOdUPnlf94HnVPX2d08pmfp6q0ZugjY2N0bFjR0RHR0ttJSUliI6Oho+PT5n7+Pj4aPQHgL1790r9XVxcYGtrq9EnLy8PR48eLXdMIiIikpcavwQWEhKCoKAgdOrUCV5eXli0aBEKCgoQHBwMABgyZAiaNm2K8PBwAMCECRPQvXt3fP311+jTpw8iIyNx/PhxrFixAgCgUCgwceJEzJkzBy1btoSLiwumT58Oe3t7BAQE1NRhEhERUS1S4wFo4MCBuHXrFsLCwpCZmQlPT09ERUVJNzGnp6fDwOB/E1WdO3fGTz/9hM8++wz/+te/0LJlS2zfvh3t2rWT+kydOhUFBQUYNWoUcnJy0LVrV0RFRcHExKTaj6+6KJVKzJgxo9SlPHo+PK+6x3OqHzyv+sHzqnu15ZwqRFWeFSMiIiJ6gdT4ByESERERVTcGICIiIpIdBiAiIiKSHQYgIiIikh0GoFpq6dKlcHZ2homJCby9vREfH19h/82bN6N169YwMTGBm5sbfvvtN43tQgiEhYXBzs4OpqamUKvVSE5O1uch1Eq6Pq/btm1D7969pU8NT0hI0GP1tZcuz+ujR48wbdo0uLm5wdzcHPb29hgyZAhu3Lih78OodXT98zpz5ky0bt0a5ubmaNiwIdRqNY4eParPQ6h1dH1O/+rDDz+EQqHAokWLdFx17afr8zp06FAoFAqNxc/PT7dFC6p1IiMjhbGxsVi9erU4f/68GDlypLC0tBRZWVll9o+NjRWGhoZi/vz54sKFC+Kzzz4T9erVE2fPnpX6zJ07V6hUKrF9+3Zx+vRp0a9fP+Hi4iIePHhQXYdV4/RxXtetWydmzZolVq5cKQCIU6dOVdPR1B66Pq85OTlCrVaLjRs3iosXL4q4uDjh5eUlOnbsWJ2HVeP08fO6fv16sXfvXpGamirOnTsnhg8fLiwsLMTNmzer67BqlD7O6VPbtm0THh4ewt7eXixcuFDPR1K76OO8BgUFCT8/P5GRkSEtd+/e1WndDEC1kJeXlxg7dqy0XlxcLOzt7UV4eHiZ/QcMGCD69Omj0ebt7S1Gjx4thBCipKRE2Nraii+//FLanpOTI5RKpdiwYYMejqB20vV5/au0tDTZBiB9nten4uPjBQBx9epV3RRdB1THec3NzRUAxL59+3RTdC2nr3N6/fp10bRpU3Hu3Dnh5OQkuwCkj/MaFBQk+vfvr5d6n+IlsFqmqKgIJ06cgFqtltoMDAygVqsRFxdX5j5xcXEa/QHA19dX6p+WlobMzEyNPiqVCt7e3uWO+aLRx3ml6juvubm5UCgUdfY7+rRVHee1qKgIK1asgEqlgoeHh+6Kr6X0dU5LSkowePBgfPLJJ2jbtq1+iq/F9PmzGhMTA2tra7i6umLMmDG4c+eOTmtnAKplbt++jeLiYumTsJ+ysbFBZmZmmftkZmZW2P/pf7UZ80Wjj/NK1XNeHz58iGnTpiEwMFA2X0apz/O6c+dO1K9fHyYmJli4cCH27t2Lxo0b6/YAaiF9ndN58+bByMgI48eP133RdYC+zqufnx/WrVuH6OhozJs3DwcOHIC/vz+Ki4t1VnuNfxUGEVF5Hj16hAEDBkAIgWXLltV0OS+E119/HQkJCbh9+zZWrlyJAQMG4OjRo7C2tq7p0uqcEydOYPHixTh58iQUCkVNl/NCGTRokPT/bm5ucHd3R4sWLRATE4OePXvq5DU4A1TLNG7cGIaGhsjKytJoz8rKgq2tbZn72NraVtj/6X+1GfNFo4/zSvo9r0/Dz9WrV7F3717ZzP4A+j2v5ubmeOmll/Dqq69i1apVMDIywqpVq3R7ALWQPs7pH3/8gZs3b8LR0RFGRkYwMjLC1atXMXnyZDg7O+vlOGqb6vqztXnz5mjcuDFSUlKev+j/jwGoljE2NkbHjh0RHR0ttZWUlCA6Oho+Pj5l7uPj46PRHwD27t0r9XdxcYGtra1Gn7y8PBw9erTcMV80+jivpL/z+jT8JCcnY9++fbCystLPAdRS1fnzWlJSgsLCwucvupbTxzkdPHgwzpw5g4SEBGmxt7fHJ598gt27d+vvYGqR6vpZvX79Ou7cuQM7OzvdFA7wMfjaKDIyUiiVShERESEuXLggRo0aJSwtLUVmZqYQQojBgweLTz/9VOofGxsrjIyMxFdffSUSExPFjBkzynwM3tLSUuzYsUOcOXNG9O/fX5aPwev6vN65c0ecOnVK7Nq1SwAQkZGR4tSpUyIjI6Paj6+m6Pq8FhUViX79+olmzZqJhIQEjcdgCwsLa+QYa4Kuz2t+fr4IDQ0VcXFx4sqVK+L48eMiODhYKJVKce7cuRo5xuqmjz8D/k6OT4Hp+rzeu3dPTJkyRcTFxYm0tDSxb98+0aFDB9GyZUvx8OFDndXNAFRLffPNN8LR0VEYGxsLLy8vceTIEWlb9+7dRVBQkEb/TZs2iVatWgljY2PRtm1bsWvXLo3tJSUlYvr06cLGxkYolUrRs2dPkZSUVB2HUqvo+ryuWbNGACi1zJgxoxqOpvbQ5Xl9+pECZS2///57NR1R7aDL8/rgwQPxj3/8Q9jb2wtjY2NhZ2cn+vXrJ+Lj46vrcGoFXf8Z8HdyDEBC6Pa83r9/X/Tu3Vs0adJE1KtXTzg5OYmRI0dKgUpXFEIIobv5JCIiIqLaj/cAERERkewwABEREZHsMAARERGR7DAAERERkewwABEREZHsMAARERGR7DAAERERkewwABEREZHsMABRndSjRw9MnDhRp2POnDkTnp6ezzWGEAKjRo1Co0aNoFAokJCQUGZbbRIbGws3NzfUq1cPAQEBzzRGTEwMFAoFcnJydFKTrsZTKBTYvn27TmqqLtOnT8eoUaNq7PWLiorg7OyM48ePV6l/TderL7XlZ8fZ2RmLFi0CoP17QxVjAKIqGzp0KBQKBT788MNS28aOHQuFQoGhQ4dWSy3btm3D7Nmzq+W1tBEVFYWIiAjs3LkTGRkZaNeuXZltz2vo0KHPHFb+LiQkBJ6enkhLS0NERIROxpQ7hUIhLSqVCl26dMH+/fsr3S8zMxOLFy/G//3f/+mttm3btqF3796wsrIqM5AbGxtjypQpmDZtWqVjlVVvef84iYiIgKWl5XNWL2/avDdUOQYg0oqDgwMiIyPx4MEDqe3hw4f46aef4Ojo+NzjP3r0qEr9GjVqhAYNGjz36+laamoq7Ozs0LlzZ9ja2sLIyKjMttokNTUVb7zxBpo1a8a/oHRozZo1yMjIQGxsLBo3boy33noLly9fLrPv05/7H374AZ07d4aTk5Pe6iooKEDXrl0xb968cvt88MEHOHToEM6fP1/hWNVRL2mq6ntDlWMAIq106NABDg4O2LZtm9S2bds2ODo6on379hp9o6Ki0LVrV1haWsLKygpvvfUWUlNTpe1XrlyBQqHAxo0b0b17d5iYmGD9+vV4/Pgxxo8fL+03bdo0BAUFacx4/P1fmc7Ozvjiiy8wbNgwNGjQAI6OjlixYoVGPdOmTUOrVq1gZmaG5s2bY/r06VUOXE+dO3cO/v7+qF+/PmxsbDB48GDcvn0bwJNZmY8//hjp6elQKBRwdnYusw0ASkpKEB4eDhcXF5iamsLDwwNbtmzReK3z58/jrbfegoWFBRo0aIBu3bohNTUVM2fOxNq1a7Fjxw5pliEmJqbMegsLCzF+/HhYW1vDxMQEXbt2xbFjxzTO/507dzBs2DAoFIpyZ4B+/PFHdOrUCQ0aNICtrS3ef/993Lx5s8JzFRsbix49esDMzAwNGzaEr68vsrOzK63rr06cOIFOnTrBzMwMnTt3RlJSksb2ZcuWoUWLFjA2Noarqyt+/PHHCmvS5vwA/7sUFx0dXWEdZbG0tIStrS3atWuHZcuW4cGDB9i7dy+AJzNEy5YtQ79+/WBubo5///vfAIDIyEj07dtXGmPdunWwsrJCYWGhxtgBAQEYPHiwVsf61ODBgxEWFga1Wl1un4YNG6JLly6IjIyscKy/16uNp7OYX331Fezs7GBlZYWxY8dq/E4WFhZiypQpaNq0KczNzeHt7a3xs/50Vmnnzp1wdXWFmZkZ3n33Xdy/fx9r166Fs7MzGjZsiPHjx6O4uFjaz9nZGbNnz0ZgYCDMzc3RtGlTLF26tMJ6z549izfeeAOmpqawsrLCqFGjkJ+fDwA4ePAg6tWrh8zMTI19Jk6ciG7duknrhw4dQrdu3WBqagoHBweMHz8eBQUF0vabN2+ib9++MDU1hYuLC9avX1+qjqq+N1QFOv1qVXqhBQUFif79+4sFCxaInj17Su09e/YUCxcuFP3799f4xt8tW7aIrVu3iuTkZHHq1CnRt29f4ebmJoqLi4UQ//vWb2dnZ7F161Zx+fJlcePGDTFnzhzRqFEjsW3bNpGYmCg+/PBDYWFhIfr37y+N3b17dzFhwgRp3cnJSTRq1EgsXbpUJCcni/DwcGFgYCAuXrwo9Zk9e7aIjY0VaWlp4pdffhE2NjZi3rx50vYZM2YIDw+Pco8/OztbNGnSRISGhorExERx8uRJ0atXL/H6668LIYTIyckRn3/+uWjWrJnIyMgQN2/eLLNNCCHmzJkjWrduLaKiokRqaqpYs2aNUCqVIiYmRgghxPXr10WjRo3E22+/LY4dOyaSkpLE6tWrxcWLF8W9e/fEgAEDhJ+fn8jIyBAZGRmisLCwzJrHjx8v7O3txW+//SbOnz8vgoKCRMOGDcWdO3fE48ePRUZGhrCwsBCLFi0SGRkZ4v79+2WOs2rVKvHbb7+J1NRUERcXJ3x8fIS/v7+0/ffffxcARHZ2thBCiFOnTgmlUinGjBkjEhISxLlz58Q333wjbt26VWldfx3P29tbxMTEiPPnz4tu3bqJzp07S6+5bds2Ua9ePbF06VKRlJQkvv76a2FoaCj2798v9QEgfv7553LfU13UUZa/v+7du3cFALFkyRJpu7W1tVi9erVITU0VV69eFXfu3BEKhULjW7Tv378vVCqV2LRpk9SWlZUljIyMpOM8ePCgMDc3r3D5z3/+U6rGp79/p06dKvMYpk2bJrp3717uMZZVrxClfzefWrNmjVCpVNJ6UFCQsLCwEB9++KFITEwUv/76qzAzMxMrVqyQ+owYMUJ07txZHDx4UKSkpIgvv/xSKJVKcenSJWnMevXqiV69eomTJ0+KAwcOCCsrK9G7d28xYMAAcf78efHrr78KY2NjERkZKY3r5OQkGjRoIMLDw0VSUpJYsmSJMDQ0FHv27JH6/PU9zM/PF3Z2duLtt98WZ8+eFdHR0cLFxUXjz7tWrVqJ+fPnS+tFRUWicePGYvXq1UIIIVJSUoS5ublYuHChuHTpkoiNjRXt27cXQ4cOlfbx9/cXHh4eIi4uThw/flx07txZmJqalvp2+creG6oaBiCqsqcB6ObNm0KpVIorV66IK1euCBMTE3Hr1q1SAejvbt26JQCIs2fPCiH+9wfwokWLNPrZ2NiIL7/8Ulp//PixcHR0rDQA/fOf/5TWS0pKhLW1tVi2bFm59Xz55ZeiY8eO0nplAWj27Nmid+/eGm3Xrl0TAERSUpIQQoiFCxcKJycnjT5/b3v48KEwMzMThw8f1ug3fPhwERgYKIQQIjQ0VLi4uIiioqIya3n6XlQkPz9f1KtXT6xfv15qKyoqEvb29hp/UKtUKrFmzZoKx/q7Y8eOCQDi3r17QojSASgwMFB06dLlmet6Ot6+ffukPrt27RIAxIMHD4QQQnTu3FmMHDlSY+z33ntPvPnmm9J6RQFIV3WU5a+vW1BQID766CNhaGgoTp8+LW2fOHGixj6nTp0SAER6erpG+5gxYzTC5tdffy2aN28uSkpKhBBPQlJycnKFS15eXqkaKwtAixcvFs7OzuUeY3n1ahOAnJycxOPHj6W29957TwwcOFAIIcTVq1eFoaGh+PPPPzXG6dmzpwgNDZXGBCBSUlKk7aNHjxZmZmbSz6YQQvj6+orRo0dL605OTsLPz09j3IEDB2qc57++hytWrBANGzYU+fn50vZdu3YJAwMDkZmZKYQQYt68eeLll1+Wtm/dulXUr19f2mf48OFi1KhRGq/5xx9/CAMDA/HgwQORlJQkAIj4+Hhpe2JiogBQKgBV9t5Q1dSumxGoTmjSpAn69OmDiIgICCHQp08fNG7cuFS/5ORkhIWF4ejRo7h9+zZKSkoAAOnp6Ro3Anfq1En6/9zcXGRlZcHLy0tqMzQ0RMeOHaX9y+Pu7i79v0KhgK2trcZlmo0bN2LJkiVITU1Ffn4+Hj9+DAsLiyof9+nTp/H777+jfv36pbalpqaiVatWVRonJSUF9+/fR69evTTai4qKpMuICQkJ6NatG+rVq1fl+sqq6dGjR+jSpYvUVq9ePXh5eSExMVGrsU6cOIGZM2fi9OnTyM7O1ngv27RpU6p/QkIC3nvvveeu66/vqZ2dHYAnlwkcHR2RmJhY6umjLl26YPHixVU6Jl3VUZ7AwEAYGhriwYMHaNKkCVatWqUxzl9/7gFI99WZmJhotI8cORKvvPIK/vzzTzRt2hQRERHSAwkAYGpqipdeeqlKx6wNU1NT3L9/v9zt5dWrjbZt28LQ0FBat7Ozw9mzZwE8ueRUXFxc6veqsLAQVlZW0rqZmRlatGghrdvY2MDZ2Vnj99TGxqbUJVsfH59S60+ftvq7xMREeHh4wNzcXGrr0qULSkpKkJSUBBsbGwwdOhSfffYZjhw5gldffRUREREYMGCAtM/p06dx5swZjctaQgiUlJQgLS0Nly5dgpGRETp27Chtb926dZn35VX23lDVMADRMxk2bBjGjRsHAOVeO+/bty+cnJywcuVK2Nvbo6SkBO3atUNRUZFGv7/+ofI8/h4WFAqF9Bd1XFwcPvjgA8yaNQu+vr5QqVSIjIzE119/XeXx8/Pz0bdv3zJvHn36l2JVxwGAXbt2oWnTphrblEolgCd/wNUWBQUF8PX1ha+vL9avX48mTZogPT0dvr6+pd7Lp3RV/1/f06d/4VcWhPXhWepYuHAh1Go1VCoVmjRpUmr733/un/4jIjs7W6N/+/bt4eHhgXXr1qF37944f/48du3aJW3/448/4O/vX2Et33//PT744IMK+/zd3bt3y6y7snotLCyQm5tbqn9OTg5UKpVGW0W/s/n5+TA0NMSJEyc0QhIAjXBT1hgVjasv1tbW6Nu3L9asWQMXFxf897//1bhfKT8/H6NHj8b48eNL7evo6IhLly5V+bUqe2+oahiA6Jn4+fmhqKgICoUCvr6+pbbfuXMHSUlJWLlypXQT4KFDhyodV6VSwcbGBseOHcNrr70GACguLsbJkyef6zN6Dh8+DCcnJ43Hda9evarVGB06dMDWrVvh7Oz8XE9ytWnTBkqlEunp6ejevXuZfdzd3bF27Vo8evSozFkgY2NjjZs6y/L05uDY2FjpKZ1Hjx7h2LFjWn2G0sWLF3Hnzh3MnTsXDg4OAFDp55C4u7sjOjoas2bN0ltdL7/8MmJjYxEUFCS1xcbGljkjVRZd1VEeW1tbrWZmWrRoAQsLC1y4cKHUrMeIESOwaNEi/Pnnn1Cr1dL7ADyZSarss6VsbGy0qh14csP/3x9sqEq9rq6u2LNnT6n+J0+erPIsKfAk+BUXF+PmzZsaNxLrypEjR0qtv/zyy2X2ffnllxEREYGCggIpuMbGxsLAwACurq5SvxEjRiAwMBDNmjVDixYtNGYXO3TogAsXLpT7M9G6dWs8fvwYJ06cwCuvvAIASEpKKvOzsCp7b6hq+BQYPRNDQ0MkJibiwoULpf51Bjx5UsHKygorVqxASkoK9u/fj5CQkCqN/fHHHyM8PBw7duxAUlISJkyYgOzsbOlf3s+iZcuWSE9PR2RkJFJTU7FkyRL8/PPPWo0xduxY3L17F4GBgTh27BhSU1Oxe/duBAcHVxpG/qpBgwaYMmUKJk2ahLVr1yI1NRUnT57EN998g7Vr1wIAxo0bh7y8PAwaNAjHjx9HcnIyfvzxR+npI2dnZ5w5cwZJSUm4fft2mU+zmZubY8yYMfjkk08QFRWFCxcuYOTIkbh//z6GDx9e5XodHR1hbGyMb775BpcvX8Yvv/xS6WcwhYaG4tixY/joo49w5swZXLx4EcuWLcPt27d1Vtcnn3yCiIgILFu2DMnJyViwYAG2bduGKVOmVGl/XdWhKwYGBlCr1WX+Q+H999/H9evXsXLlSgwbNkxj29NLYBUtf/3IiLt37yIhIQEXLlwA8OQv2YSEhFJPMP3xxx/o3bu31vWOGTMGly5dwvjx46Wf0QULFmDDhg2YPHlylc9Hq1at8MEHH2DIkCHYtm0b0tLSEB8fj/DwcI0ZsGcVGxuL+fPn49KlS1i6dCk2b96MCRMmlNn3gw8+gImJCYKCgnDu3Dn8/vvv+PjjjzF48GCNcOnr6wsLCwvMmTMHwcHBGmNMmzYNhw8fxrhx45CQkIDk5GTs2LFDmkl3dXWFn58fRo8ejaNHj+LEiRMYMWJEmbOplb03VDUMQPTMLCwsyr2HxsDAAJGRkThx4gTatWuHSZMm4csvv6zSuNOmTUNgYCCGDBkCHx8f1K9fH76+vs91r0G/fv0wadIkjBs3Dp6enjh8+DCmT5+u1Rj29vaIjY1FcXExevfuDTc3N0ycOBGWlpYwMNDuV2n27NmYPn06wsPD8fLLL8PPzw+7du2Ci4sLAMDKygr79+9Hfn4+unfvjo4dO2LlypXSbNDIkSPh6uqKTp06oUmTJoiNjS3zdebOnYt33nkHgwcPRocOHZCSkoLdu3ejYcOGVa61SZMmiIiIwObNm9GmTRvMnTsXX331VYX7tGrVCnv27MHp06fh5eUFHx8f7NixQ5o500VdAQEBWLx4Mb766iu0bdsW33//PdasWYMePXpUeQxd1KFLI0aMQGRkZKnLNSqVCu+88w7q16//3B+A+csvv6B9+/bo06cPAGDQoEFo3749li9fLvWJi4tDbm4u3n33Xa3rbd68OQ4ePIiLFy9CrVbD29sbmzZtwubNm+Hn56dVrWvWrMGQIUMwefJkuLq6IiAgAMeOHdPJZ45NnjwZx48fR/v27TFnzhwsWLCgzNls4Ml9Rrt378bdu3fxyiuv4N1330XPnj3x7bffavQzMDDA0KFDUVxcjCFDhmhsc3d3x4EDB3Dp0iV069YN7du3R1hYGOzt7TWO197eHt27d8fbb7+NUaNGwdraWmOcqr43VDmFEELUdBFEFSkpKcHLL7+MAQMG1MpPfybSFSEEvL29MWnSJAQGBmps69mzJ9q2bYslS5bovY6BAwfCw8MD//rXvyrsV1G9tZmzszMmTpyo86/TAYDhw4fj1q1b+OWXX3Q+NlD194Yqx3uAqNa5evUq9uzZg+7du6OwsBDffvst0tLS8P7779d0aUR6pVAosGLFCulJKODJTcYxMTGIiYnBd999p/caioqK4ObmhkmTJlXat6x65So3Nxdnz57FTz/9pLfwo817Q5XjDBDVOteuXcOgQYNw7tw5CCHQrl07zJ07V7opmkhOnJ2dkZ2djenTp1f5/iaqmD5mgHr06IH4+HiMHj0aCxcu1Nm4pD8MQERERCQ7vAmaiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGSHAYiIiIhkhwGIiIiIZIcBiIiIiGTn/wH65C/smY+XhwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = 1\n",
    "plt.hist(me_alco[:, j], bins=30); \n",
    "plt.xlabel(f'Marginal effect of alcohol on Pr(y={j}) ({y_values_lab[j]})'); \n",
    "plt.ylabel('Bootstrap samples'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function to make a semi-nice table to print the coefficients, and their 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def me_table(me_coeff, me_se, **kwargs):\n",
    "    table = np.column_stack(\n",
    "        (me_coeff, me_coeff -1.96*me_se, me_coeff +1.96*me_se)\n",
    "    )\n",
    "    print(tabulate(table, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def me_table(me: np.ndarray): \n",
    "    assert me.ndim == 2 \n",
    "    n_boot,J = me.shape \n",
    "    \n",
    "    m = me.mean(0)\n",
    "    se = me.std(0)\n",
    "    tab = pd.DataFrame({\n",
    "                  'Mean m.e.': m, \n",
    "                  '-1.96 se':  m-se*1.96,\n",
    "                  '+1.96 se':  m+se*1.96\n",
    "                 },\n",
    "                index=y_values_lab)\n",
    "    return tab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean m.e.</th>\n",
       "      <th>-1.96 se</th>\n",
       "      <th>+1.96 se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Out of labor force</th>\n",
       "      <td>0.0254</td>\n",
       "      <td>-0.0070</td>\n",
       "      <td>0.0578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unemployed</th>\n",
       "      <td>0.0146</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>0.0452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employed</th>\n",
       "      <td>-0.0400</td>\n",
       "      <td>-0.0704</td>\n",
       "      <td>-0.0096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean m.e.  -1.96 se  +1.96 se\n",
       "Out of labor force     0.0254   -0.0070    0.0578\n",
       "Unemployed             0.0146   -0.0159    0.0452\n",
       "Employed              -0.0400   -0.0704   -0.0096"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_table(me_alco).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean m.e.</th>\n",
       "      <th>-1.96 se</th>\n",
       "      <th>+1.96 se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Out of labor force</th>\n",
       "      <td>-0.0090</td>\n",
       "      <td>-0.0139</td>\n",
       "      <td>-0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unemployed</th>\n",
       "      <td>-0.0066</td>\n",
       "      <td>-0.0112</td>\n",
       "      <td>-0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employed</th>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean m.e.  -1.96 se  +1.96 se\n",
       "Out of labor force    -0.0090   -0.0139   -0.0040\n",
       "Unemployed            -0.0066   -0.0112   -0.0020\n",
       "Employed               0.0156    0.0113    0.0198"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_table(me_educ).round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
